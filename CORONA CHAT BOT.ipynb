{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting newspaper3k\n",
      "  Downloading https://files.pythonhosted.org/packages/d7/b9/51afecb35bb61b188a4b44868001de348a0e8134b4dfa00ffc191567c4b9/newspaper3k-0.2.8-py3-none-any.whl (211kB)\n",
      "Requirement already satisfied: requests>=2.10.0 in c:\\users\\kushal\\anaconda3\\lib\\site-packages (from newspaper3k) (2.22.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\kushal\\anaconda3\\lib\\site-packages (from newspaper3k) (2.8.0)\n",
      "Collecting cssselect>=0.9.2 (from newspaper3k)\n",
      "  Downloading https://files.pythonhosted.org/packages/3b/d4/3b5c17f00cce85b9a1e6f91096e1cc8e8ede2e1be8e96b87ce1ed09e92c5/cssselect-1.1.0-py2.py3-none-any.whl\n",
      "Collecting tldextract>=2.0.1 (from newspaper3k)\n",
      "  Downloading https://files.pythonhosted.org/packages/7e/62/b6acd3129c5615b9860e670df07fd55b76175b63e6b7f68282c7cad38e9e/tldextract-3.1.0-py2.py3-none-any.whl (87kB)\n",
      "Requirement already satisfied: nltk>=3.2.1 in c:\\users\\kushal\\anaconda3\\lib\\site-packages (from newspaper3k) (3.4.5)\n",
      "Collecting tinysegmenter==0.3 (from newspaper3k)\n",
      "  Downloading https://files.pythonhosted.org/packages/17/82/86982e4b6d16e4febc79c2a1d68ee3b707e8a020c5d2bc4af8052d0f136a/tinysegmenter-0.3.tar.gz\n",
      "Collecting feedfinder2>=0.0.4 (from newspaper3k)\n",
      "  Downloading https://files.pythonhosted.org/packages/35/82/1251fefec3bb4b03fd966c7e7f7a41c9fc2bb00d823a34c13f847fd61406/feedfinder2-0.0.4.tar.gz\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in c:\\users\\kushal\\anaconda3\\lib\\site-packages (from newspaper3k) (4.8.0)\n",
      "Requirement already satisfied: lxml>=3.6.0 in c:\\users\\kushal\\anaconda3\\lib\\site-packages (from newspaper3k) (4.4.1)\n",
      "Collecting feedparser>=5.2.1 (from newspaper3k)\n",
      "  Downloading https://files.pythonhosted.org/packages/1c/21/faf1bac028662cc8adb2b5ef7a6f3999a765baa2835331df365289b0ca56/feedparser-6.0.2-py3-none-any.whl (80kB)\n",
      "Collecting jieba3k>=0.35.1 (from newspaper3k)\n",
      "  Downloading https://files.pythonhosted.org/packages/a9/cb/2c8332bcdc14d33b0bedd18ae0a4981a069c3513e445120da3c3f23a8aaa/jieba3k-0.35.1.zip (7.4MB)\n",
      "Requirement already satisfied: PyYAML>=3.11 in c:\\users\\kushal\\anaconda3\\lib\\site-packages (from newspaper3k) (5.1.2)\n",
      "Requirement already satisfied: Pillow>=3.3.0 in c:\\users\\kushal\\anaconda3\\lib\\site-packages (from newspaper3k) (6.2.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\kushal\\anaconda3\\lib\\site-packages (from requests>=2.10.0->newspaper3k) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\kushal\\anaconda3\\lib\\site-packages (from requests>=2.10.0->newspaper3k) (1.24.2)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\kushal\\anaconda3\\lib\\site-packages (from requests>=2.10.0->newspaper3k) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kushal\\anaconda3\\lib\\site-packages (from requests>=2.10.0->newspaper3k) (2019.9.11)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kushal\\anaconda3\\lib\\site-packages (from python-dateutil>=2.5.3->newspaper3k) (1.12.0)\n",
      "Requirement already satisfied: filelock>=3.0.8 in c:\\users\\kushal\\anaconda3\\lib\\site-packages (from tldextract>=2.0.1->newspaper3k) (3.0.12)\n",
      "Collecting requests-file>=1.4 (from tldextract>=2.0.1->newspaper3k)\n",
      "  Downloading https://files.pythonhosted.org/packages/77/86/cdb5e8eaed90796aa83a6d9f75cfbd37af553c47a291cd47bc410ef9bdb2/requests_file-1.5.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: soupsieve>=1.2 in c:\\users\\kushal\\anaconda3\\lib\\site-packages (from beautifulsoup4>=4.4.1->newspaper3k) (1.9.3)\n",
      "Collecting sgmllib3k (from feedparser>=5.2.1->newspaper3k)\n",
      "  Downloading https://files.pythonhosted.org/packages/9e/bd/3704a8c3e0942d711c1299ebf7b9091930adae6675d7c8f476a7ce48653c/sgmllib3k-1.0.0.tar.gz\n",
      "Building wheels for collected packages: tinysegmenter, feedfinder2, jieba3k, sgmllib3k\n",
      "  Building wheel for tinysegmenter (setup.py): started\n",
      "  Building wheel for tinysegmenter (setup.py): finished with status 'done'\n",
      "  Created wheel for tinysegmenter: filename=tinysegmenter-0.3-cp37-none-any.whl size=13542 sha256=1aac946ff3b560996a0ac07e26d9d6ec8c17acc49002510ed4fd0b326da2475c\n",
      "  Stored in directory: C:\\Users\\kushal\\AppData\\Local\\pip\\Cache\\wheels\\81\\2b\\43\\a02ede72324dd40cdd7ca53aad718c7710628e91b8b0dc0f02\n",
      "  Building wheel for feedfinder2 (setup.py): started\n",
      "  Building wheel for feedfinder2 (setup.py): finished with status 'done'\n",
      "  Created wheel for feedfinder2: filename=feedfinder2-0.0.4-cp37-none-any.whl size=3362 sha256=1c396ab8198204f20d3bd75adbc037f101af29a5d49a23a6f8dc3d76a381cfa9\n",
      "  Stored in directory: C:\\Users\\kushal\\AppData\\Local\\pip\\Cache\\wheels\\de\\03\\ca\\778e3a7a627e3d98836cc890e7cb40c7575424cfd3340f40ed\n",
      "  Building wheel for jieba3k (setup.py): started\n",
      "  Building wheel for jieba3k (setup.py): finished with status 'done'\n",
      "  Created wheel for jieba3k: filename=jieba3k-0.35.1-cp37-none-any.whl size=7398414 sha256=307c3813a5ba858cb07af1c10895f68ab47e7b2bae7dc953c066265137753784\n",
      "  Stored in directory: C:\\Users\\kushal\\AppData\\Local\\pip\\Cache\\wheels\\83\\15\\9c\\a3f1f67e7f7181170ad37d32e503c35da20627c013f438ed34\n",
      "  Building wheel for sgmllib3k (setup.py): started\n",
      "  Building wheel for sgmllib3k (setup.py): finished with status 'done'\n",
      "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-cp37-none-any.whl size=6070 sha256=1820e6b28520e255a439e08a7d346fea74f7f0dedf82a1c38174d1c9e3a84591\n",
      "  Stored in directory: C:\\Users\\kushal\\AppData\\Local\\pip\\Cache\\wheels\\f1\\80\\5a\\444ba08a550cdd241bd9baf8bae44be750efe370adb944506a\n",
      "Successfully built tinysegmenter feedfinder2 jieba3k sgmllib3k\n",
      "Installing collected packages: cssselect, requests-file, tldextract, tinysegmenter, feedfinder2, sgmllib3k, feedparser, jieba3k, newspaper3k\n",
      "Successfully installed cssselect-1.1.0 feedfinder2-0.0.4 feedparser-6.0.2 jieba3k-0.35.1 newspaper3k-0.2.8 requests-file-1.5.1 sgmllib3k-1.0.0 tinysegmenter-0.3 tldextract-3.1.0\n",
      "Collecting gTTS\n",
      "  Downloading https://files.pythonhosted.org/packages/5f/b9/94e59337107be134b21ce395a29fc0715b707b560108d6797de2d93e1178/gTTS-2.2.2-py3-none-any.whl\n",
      "Requirement already satisfied: six in c:\\users\\kushal\\anaconda3\\lib\\site-packages (from gTTS) (1.12.0)\n",
      "Requirement already satisfied: click in c:\\users\\kushal\\anaconda3\\lib\\site-packages (from gTTS) (7.0)\n",
      "Requirement already satisfied: requests in c:\\users\\kushal\\anaconda3\\lib\\site-packages (from gTTS) (2.22.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kushal\\anaconda3\\lib\\site-packages (from requests->gTTS) (2019.9.11)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\kushal\\anaconda3\\lib\\site-packages (from requests->gTTS) (1.24.2)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\kushal\\anaconda3\\lib\\site-packages (from requests->gTTS) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\kushal\\anaconda3\\lib\\site-packages (from requests->gTTS) (3.0.4)\n",
      "Installing collected packages: gTTS\n",
      "Successfully installed gTTS-2.2.2\n"
     ]
    }
   ],
   "source": [
    "#first install the newspaper\n",
    "!pip install newspaper3k\n",
    "#importig the libraies\n",
    "from newspaper import Article\n",
    "import numpy as np\n",
    "import warnings\n",
    "import nltk\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "nltk.download('punkt',quiet=True)\n",
    "nltk.download('wordnet',quiet=True)\n",
    "!pip install gTTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "article=Article('https://en.wikipedia.org/wiki/Coronavirus_disease_2019')\n",
    "article.download()\n",
    "article.parse()\n",
    "article.nlp()\n",
    "warnings.filterwarnings('ignore')\n",
    "#print(article.title)\n",
    "#print(article.text)\n",
    "#print(article.top_image)\n",
    "corpus=article.text\n",
    "#print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=corpus\n",
    "import random\n",
    "\n",
    "sent_tokens=nltk.sent_tokenize(text)\n",
    "#print(sent_tokens)\n",
    "\n",
    "#print(string.punctuation)\n",
    "\n",
    "remove_punct=dict((ord(punct),None) for punct in string.punctuation)\n",
    "#print(remove_punct)\n",
    "\n",
    "\n",
    "def lemmalize(text):\n",
    "  return nltk.word_tokenize(text.lower().translate(remove_punct))\n",
    "#print(lemmalize(text))\n",
    "\n",
    "greetings=['hi','hello','heyy','namasthe','namaskara','whats up']\n",
    "output=['hi','hello','heyyy','namasthe heli','namaskara heli','Hey! Whats up']\n",
    "\n",
    "def greeting(user_responses):\n",
    "  user_responses=user_responses.lower()\n",
    "  for word in user_responses.split():\n",
    "    if word in greetings:\n",
    "      return random.choice(output)\n",
    "\n",
    "\n",
    "def response(user_resposnse):\n",
    "  robo_response=''\n",
    " \n",
    "  sent_tokens.append(user_response)\n",
    "  \n",
    "  #print(sent_tokens[-1])\n",
    "\n",
    "  tfidf=TfidfVectorizer(tokenizer=lemmalize,stop_words='english')\n",
    "  tfid=tfidf.fit_transform(sent_tokens)\n",
    "  #print(tfid)\n",
    "\n",
    "  vals=cosine_similarity(tfid[-1],tfid)\n",
    "  #print(vals)\n",
    "  idx=vals.argsort()[0][-2]\n",
    "  #print(idx)\n",
    "  #print(sent_tokens[idx])\n",
    "\n",
    "  flat=vals.flatten()\n",
    "  flat.sort()\n",
    "  score=flat[-2]\n",
    "  #print(score)\n",
    "\n",
    "  if(score==0):\n",
    "    robo_response='Sorry Cannot Find The Answer'\n",
    "  else:\n",
    "    robo_response=sent_tokens[idx]\n",
    "  return (robo_response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi i am a CHATBOT I can give information about CoronaVirus(Covid-19)\n",
      "hi\n",
      "CHATBOT:Hey! Whats up\n",
      "what is coronavirus?\n",
      "CHATBOT:For other diseases caused by coronaviruses, see Coronavirus diseases\n",
      "\n",
      "Medical condition\n",
      "\n",
      "Coronavirus disease 2019 (COVID-19), also known as the coronavirus or COVID, is a contagious disease caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2).\n",
      "where it is first identified?\n",
      "CHATBOT:The first known case was identified in Wuhan, China, in December 2019.\n",
      "Symptoms of covid-19?\n",
      "CHATBOT:[366][367] Symptoms in cats include respiratory (such as a cough) and digestive symptoms.\n",
      "what are the common symptoms include?\n",
      "CHATBOT:The disease may take a mild course with few or no symptoms, resembling other common upper respiratory diseases such as the common cold.\n",
      "what does cdc recommends?\n",
      "CHATBOT:[165] When not wearing a mask, the CDC recommends covering the mouth and nose with a tissue when coughing or sneezing and recommends using the inside of the elbow if no tissue is available.\n",
      "what are the preventive measures?\n",
      "CHATBOT:[160][161] This recommendation is meant to reduce the spread of the disease by asymptomatic and pre-symptomatic individuals and is complementary to established preventive measures such as social distancing.\n",
      "how do most people recover?\n",
      "CHATBOT:[207] Mild cases typically recover within two weeks, while those with severe or critical diseases may take three to six weeks to recover.\n",
      "thank you\n",
      "CHATBOT:SEE YOU SOON \n"
     ]
    }
   ],
   "source": [
    "flag=True\n",
    "print('Hi i am a CHATBOT I can give information about CoronaVirus(Covid-19)')\n",
    "\n",
    "while(flag):\n",
    "\n",
    "  user_response=input()\n",
    "  user_response=user_response.lower()\n",
    "\n",
    "  if(user_response!='bye'):\n",
    "    if(user_response=='thank you' or user_response=='thank youu'):\n",
    "      flag=False\n",
    "      print('CHATBOT:'+ 'SEE YOU SOON ')\n",
    "    else:\n",
    "      if(greeting(user_response)!=None):\n",
    "        print('CHATBOT:'+ str(greeting(user_response)))\n",
    "      else:\n",
    "        print('CHATBOT:'+str(response(user_response)))\n",
    "  else:\n",
    "    flag=False\n",
    "    print('CHATBOT:'+ 'SEE YOU SOON')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
